{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 关键部分，怎样构建损失函数来训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_kd(outputs, labels, teacher_outputs, T=20, alpha=0.5):\n",
    "\n",
    "    hard_loss = F.cross_entropy(outputs, labels) * (1. - alpha)\n",
    "    \n",
    "    soft_loss = nn.KLDivLoss(reduction='batchmean')(F.log_softmax(outputs/T, dim=1),\n",
    "                             F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T)\n",
    "    return hard_loss + soft_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(path, label):\n",
    "    image_dir = sorted(os.listdir(path))\n",
    "    x = np.zeros((len(image_dir), 128, 128, 3), dtype=np.uint8)\n",
    "    y = np.zeros((len(image_dir)), dtype=np.uint8)\n",
    "    for i, file in enumerate(image_dir):\n",
    "        print(os.path.join(path, file))\n",
    "        img = cv2.imread(os.path.join(path, file))\n",
    "        x[i, :, :] = cv2.resize(img,(128, 128))\n",
    "        if label:\n",
    "          y[i] = int(file.split(\"_\")[0])\n",
    "    if label:\n",
    "      return x, y\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "workspace_dir = \"G:/Model_Compress/Dataset\"\n",
    "print(\"Reading data\")\n",
    "train_x, train_y = readfile(os.path.join(workspace_dir, \"training\"), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.RandomRotation(15), \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                                    \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x, y=None, transform=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        if y is not None:\n",
    "            self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index):\n",
    "        X = self.x[index]\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        if self.y is not None:\n",
    "            Y = self.y[index]\n",
    "            return X, Y\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_set = ImgDataset(train_x, train_y, train_transform)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = train_loader\n",
    "val_set = train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentNet, self).__init__()\n",
    "        \n",
    "        # input size: (3, 128, 128)\n",
    "        self.CNN = nn.Sequential(\n",
    "            nn.Conv2d(3, 3, 3, 1, 1, groups=3),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(3, 64, 1),\n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "            \n",
    "            nn.Conv2d(64, 64, 3, 1, 1, groups=64),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 1),\n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "            \n",
    "            nn.Conv2d(128, 128, 3, 1, 1, groups=128),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 1),\n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "            \n",
    "            nn.Conv2d(256, 256, 3, 1, 1, groups=256),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, 1),\n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "            \n",
    "            nn.Conv2d(512, 512, 3, 1, 1, groups=512),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 1),\n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "            \n",
    "            # Channel x H x W -> C x 1 x 1\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.CNN(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_param_requires_grad(model, feature_extract):\n",
    "    count = 0\n",
    "    if feature_extract:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "            # print(\"fine tuning\")\n",
    "    elif not feature_extract:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "            count += 1\n",
    "\n",
    "teacher_net = models.resnet18(pretrained=False)\n",
    "set_param_requires_grad(teacher_net, True)  \n",
    "fc_new = teacher_net.fc.in_features\n",
    "teacher_net.fc = nn.Linear(fc_new, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/015] 12.65 sec(s) Train Acc: 0.525000 Loss: 0.044899 | Val Acc: 0.500000 loss: 0.046675\n",
      "[002/015] 10.82 sec(s) Train Acc: 0.632500 Loss: 0.040311 | Val Acc: 0.500000 loss: 0.050105\n",
      "[003/015] 10.86 sec(s) Train Acc: 0.637500 Loss: 0.040142 | Val Acc: 0.757500 loss: 0.038593\n",
      "[004/015] 11.23 sec(s) Train Acc: 0.667500 Loss: 0.037705 | Val Acc: 0.675000 loss: 0.037316\n",
      "[005/015] 11.51 sec(s) Train Acc: 0.695000 Loss: 0.038062 | Val Acc: 0.700000 loss: 0.038292\n",
      "[006/015] 11.57 sec(s) Train Acc: 0.672500 Loss: 0.038077 | Val Acc: 0.767500 loss: 0.034274\n",
      "[007/015] 11.55 sec(s) Train Acc: 0.747500 Loss: 0.034700 | Val Acc: 0.712500 loss: 0.037826\n",
      "[008/015] 11.56 sec(s) Train Acc: 0.720000 Loss: 0.035251 | Val Acc: 0.757500 loss: 0.033832\n",
      "[009/015] 11.56 sec(s) Train Acc: 0.767500 Loss: 0.033306 | Val Acc: 0.665000 loss: 0.035366\n",
      "[010/015] 11.56 sec(s) Train Acc: 0.747500 Loss: 0.033239 | Val Acc: 0.757500 loss: 0.032490\n",
      "[011/015] 11.56 sec(s) Train Acc: 0.745000 Loss: 0.032800 | Val Acc: 0.860000 loss: 0.030278\n",
      "[012/015] 11.55 sec(s) Train Acc: 0.752500 Loss: 0.033234 | Val Acc: 0.835000 loss: 0.030172\n",
      "[013/015] 11.56 sec(s) Train Acc: 0.797500 Loss: 0.031469 | Val Acc: 0.817500 loss: 0.030081\n",
      "[014/015] 11.56 sec(s) Train Acc: 0.785000 Loss: 0.032181 | Val Acc: 0.830000 loss: 0.029553\n",
      "[015/015] 11.59 sec(s) Train Acc: 0.770000 Loss: 0.032360 | Val Acc: 0.797500 loss: 0.030042\n"
     ]
    }
   ],
   "source": [
    "model = teacher_net.cuda()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epoch = 15\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    model.train() \n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_pred = model(data[0].cuda()) \n",
    "        \n",
    "        batch_loss = loss(train_pred, data[1].cuda()) \n",
    "        batch_loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "        train_loss += batch_loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            val_pred = model(data[0].cuda())\n",
    "            batch_loss = loss(val_pred, data[1].cuda())\n",
    "\n",
    "            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "            val_loss += batch_loss.item()\n",
    "\n",
    "        #將結果 print 出來\n",
    "        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
    "            (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
    "             train_acc/train_set.__len__(), train_loss/train_set.__len__(), val_acc/val_set.__len__(), val_loss/val_set.__len__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.state_dict()\n",
    "torch.save(weights, \"ResNet18_landslide.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_net.load_state_dict(torch.load(\"ResNet18_landslide.pth\"))\n",
    "teacher_net.cuda()\n",
    "student_net = StudentNet().cuda()\n",
    "optimizer = optim.AdamW(student_net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0: train loss: 0.3515, acc 0.7350 valid loss: 0.5751, acc 0.5000\n",
      "epoch   1: train loss: 0.2528, acc 0.8550 valid loss: 0.5973, acc 0.5375\n",
      "epoch   2: train loss: 0.2419, acc 0.8650 valid loss: 0.2278, acc 0.8775\n",
      "epoch   3: train loss: 0.2344, acc 0.8875 valid loss: 0.1984, acc 0.9275\n",
      "epoch   4: train loss: 0.2108, acc 0.9050 valid loss: 0.1896, acc 0.9400\n",
      "epoch   5: train loss: 0.2394, acc 0.8675 valid loss: 0.2024, acc 0.9175\n",
      "epoch   6: train loss: 0.2194, acc 0.9150 valid loss: 0.1842, acc 0.9375\n",
      "epoch   7: train loss: 0.2191, acc 0.9275 valid loss: 0.1920, acc 0.9550\n",
      "epoch   8: train loss: 0.2208, acc 0.8875 valid loss: 0.1793, acc 0.9575\n",
      "epoch   9: train loss: 0.2121, acc 0.9300 valid loss: 0.1813, acc 0.9500\n",
      "epoch  10: train loss: 0.2314, acc 0.9075 valid loss: 0.2034, acc 0.9175\n",
      "epoch  11: train loss: 0.2022, acc 0.9275 valid loss: 0.1779, acc 0.9600\n",
      "epoch  12: train loss: 0.2182, acc 0.8900 valid loss: 0.1868, acc 0.9375\n",
      "epoch  13: train loss: 0.2207, acc 0.9050 valid loss: 0.1992, acc 0.9575\n",
      "epoch  14: train loss: 0.2002, acc 0.9275 valid loss: 0.1809, acc 0.9525\n"
     ]
    }
   ],
   "source": [
    "def run_epoch(dataloader, update=True, alpha=0.5):\n",
    "    total_num, total_hit, total_loss = 0, 0, 0\n",
    "    for now_step, batch_data in enumerate(dataloader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs, hard_labels = batch_data\n",
    "        inputs = inputs.cuda()\n",
    "        hard_labels = torch.LongTensor(hard_labels).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            soft_labels = teacher_net(inputs)\n",
    "\n",
    "        if update:\n",
    "            logits = student_net(inputs)\n",
    "            loss = loss_fn_kd(logits, hard_labels, soft_labels, 20, alpha)\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                logits = student_net(inputs)\n",
    "                loss = loss_fn_kd(logits, hard_labels, soft_labels, 20, alpha)\n",
    "            \n",
    "        total_hit += torch.sum(torch.argmax(logits, dim=1) == hard_labels).item()\n",
    "        total_num += len(inputs)\n",
    "\n",
    "        total_loss += loss.item() * len(inputs)\n",
    "    return total_loss / total_num, total_hit / total_num\n",
    "\n",
    "\n",
    "\n",
    "teacher_net.eval()\n",
    "now_best_acc = 0\n",
    "for epoch in range(15):\n",
    "    student_net.train()\n",
    "    train_loss, train_acc = run_epoch(train_loader, update=True)\n",
    "    student_net.eval()\n",
    "    valid_loss, valid_acc = run_epoch(val_loader, update=False)\n",
    "\n",
    "    # 存下最好的model。\n",
    "    if valid_acc > now_best_acc:\n",
    "        now_best_acc = valid_acc\n",
    "        torch.save(student_net.state_dict(), 'student_model.bin')\n",
    "    print('epoch {:>3d}: train loss: {:6.4f}, acc {:6.4f} valid loss: {:6.4f}, acc {:6.4f}'.format(\n",
    "        epoch, train_loss, train_acc, valid_loss, valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_net = StudentNet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_net.load_state_dict(torch.load(\"student_model.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.2",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
